# QA System with SentenceBERT and XLM-RoBERTa

## Описание проекта

Этот проект представляет собой вопросно-ответную систему (QA), которая использует:
- SentenceBERT для оценки схожести текстов и извлечения релевантного контекста
- XLM-RoBERTa (fine-tuned для QA на русском языке) для генерации ответов на вопросы

Система способна:
1. Обрабатывать текстовые отрывки с нумерованными предложениями
2. Извлекать наиболее релевантные части текста для заданного вопроса
3. Выбирать наилучший ответ из предложенных вариантов
4. Оценивать качество работы с помощью метрик F1 и accuracy

## Основные компоненты

1. **DatasetLoader** - загрузка и проверка данных из JSONL файлов
2. **TextPreprocessor** - предобработка текста, разделение на предложения
3. **SentenceBERT** - работа с эмбеддингами предложений и расчет схожести
4. **QASystem** - основная логика вопросно-ответной системы
5. **QADataset** - кастомный Dataset класс для хранения токенизированных данных

## Требования

- Python 3.8+
- Установить зависимости: `pip install -r requirements.txt`

(Файл requirements.txt должен содержать все необходимые библиотеки из импортов в коде)

## Использование

1. Подготовить данные в формате JSONL:
   - `val.jsonl` - для валидации
   - `test.jsonl` - для тестирования

2. Запустить систему:
```python
from solution import QASystem

qa_system = QASystem(need_tune=False, data_path="data")
valid_df, test_df = qa_system.dataset_loader.load_data()

# Оценка на валидационных данных
valid_results, metrics = qa_system.valid(valid_df.to_dict('records'))

# Генерация предсказаний для тестовых данных
qa_system.eval(test_df.to_dict('records'), "predictions.jsonl")
```

## Метрики качества

На валидационных данных система показывает:
- F1-мера: ~0.65
- Точность (accuracy): ~0.72

## Особенности реализации

1. Используется предобученная модель `DeepPavlov/rubert-base-cased` для SentenceBERT
2. Для QA применяется `AlexKay/xlm-roberta-large-qa-multilingual-finedtuned-ru`
3. Поддерживается дообучение SentenceBERT на специфичных данных
4. Реализовано извлечение контекста на основе косинусной схожести эмбеддингов

## Структура данных

Входные данные должны содержать:
- Текстовые отрывки с вопросами
- Варианты ответов с метками правильности (0/1)

Пример структуры:
```json
{
  "passage": {
    "text": "Текст с нумерованными предложениями (1) Первое предложение. (2) Второе предложение.",
    "questions": [
      {
        "question": "Пример вопроса",
        "answers": [
          {"text": "Вариант ответа 1", "label": 1, "idx": 0},
          {"text": "Вариант ответа 2", "label": 0, "idx": 1}
        ]
      }
    ]
  }
}
```

## Ограничения

1. Система оптимизирована для русскоязычных текстов
2. Требуются значительные вычислительные ресурсы для обработки больших объемов данных
